{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uZ3Rb6JRfF3"
   },
   "source": [
    "# Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data generated in Session 1 or the provided data splits (see Absalon, W7 Lab)\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_pickle(\"train_dataframe.pkl\")\n",
    "df_test = pd.read_pickle(\"test_dataframe.pkl\")\n",
    "\n",
    "# In this session, we will also need to load the metadata file (see Absalon, W9 Lab)\n",
    "meta_file = 'meta_All_Beauty.json'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XIYb2Pxi6_Ie"
   },
   "source": [
    "# Exercise 1 {-}\n",
    "\n",
    "Load the [metadata file](https://absalon.ku.dk/courses/80396/files/9386857?module_item_id=2657111) from Absalon and discard any item that was not rated by our subset of users (not in training or test sets). You can refer to the [original metadata file](https://nijianmo.github.io/amazon/index.html) if you want to look up more explanations about the columns of the metada file. Apply preprocessing in this order: lowercasing, tokenizing, stemming, and stopwords removal (including punctuation) to clean up the text from the `title`. Report the vocabulary size before and after the preprocessing. You may have to specify the language for these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKbUQSlc65kO",
    "outputId": "f43a9bb4-8d8f-4653-df9b-613fa23e1bb5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the metadata (items)\n",
    "item_metadata = pd.read_json(\"meta_All_Beauty.json\", lines=True)\n",
    "all_rated_items_set = set(df_train.asin.tolist() + df_test.asin.tolist())\n",
    "\n",
    "# Discard items that weren't rated by our subset of users\n",
    "filtered_item_metadata = item_metadata[item_metadata.asin.isin(all_rated_items_set)].drop_duplicates(['asin', 'title'])\n",
    "item_titles = filtered_item_metadata.title.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_item_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rd0RbH-k9y1H",
    "outputId": "ab4de5c7-9660-47ab-875f-cde5077324f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/danielpenchev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/danielpenchev/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danielpenchev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import string\n",
    "\n",
    "corpus =  \" \".join([item_descr for item_descr in filtered_item_metadata.title.tolist()])\n",
    "#lower_case_corpus = corpus.lower()\n",
    "tokenized_corpus = word_tokenize(corpus, language=\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokenized_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_tokenized_corpus = [stemmer.stem(token) for token in tokenized_corpus]\n",
    "stops_words_english = set(stopwords.words('english')+ list(string.punctuation)) \n",
    "corpus_filtered_tokens = set([token for token in stemmed_tokenized_corpus if token not in stops_words_english])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_filtered_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Blr1jgoHLbFU"
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "Representation in vector spaces.\n",
    "\n",
    "## 2.1\n",
    "\n",
    "Represent all the items from Exercise 1 in a TF-IDF space. Interpret the meaning of the TF-IDF matrix dimensions. Be careful with multiple instances of preprocessing in the process, as default settings for creating the TF-IDF space may include some.\n",
    "\n",
    "Tip: You may use the library [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    lower_case_corpus = text.lower()\n",
    "    tokenized_corpus = word_tokenize(lower_case_corpus)\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokenized_corpus = [stemmer.stem(token) for token in tokenized_corpus]\n",
    "    stops_words_english = set(stopwords.words('english')) | set(string.punctuation)\n",
    "    return \" \".join([token for token in stemmed_tokenized_corpus if token not in stops_words_english])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDndolvDLznV",
    "outputId": "35ddbd7f-2bcf-4289-9436-97cbc3ca26bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aqua', 'velva', 'after', 'shave', ',', 'classic', 'ice', 'blue', ',', '7', 'ounce']\n",
      "['citre', 'shine', 'moisture', 'burst', 'shampoo', '-', '16', 'fl', 'oz']\n",
      "['nars', 'blush', ',', 'taj', 'mahal']\n",
      "['avalon', 'organics', 'wrinkle', 'therapy', 'coq10', 'cleansing', 'milk', ',', '8.50', 'oz']\n",
      "['zum', 'zum', 'bar', 'anise', 'lavender', ',', '3', 'ounce']\n",
      "['yardley', 'by', 'yardley', 'of', 'london', 'unisexs', 'lay', 'it', 'on', 'thick', 'hand', '&', 'amp', ';', 'foot', 'cream', '5.3', 'oz']\n",
      "['fruits', '&', 'amp', ';', 'passion', 'blue', 'refreshing', 'shower', 'gel', '-', '6.7', 'fl', '.', 'oz', '.']\n",
      "['waterpik', 'ultra', 'water', 'flosser']\n",
      "['aqua', 'velva', 'after', 'shave', ',', 'classic', 'ice', 'blue', ',', '3.5', 'ounce']\n",
      "['waterpik', 'ultra', 'water', 'flosser']\n",
      "['fresh', 'eau', 'de', 'parfum', ',', 'sugar', 'lemon', ',', '3.4', 'oz']\n",
      "['crest', 'pro-health', 'multi-protection', 'rinse', ',', 'cool', 'wintergreen', ',', '33.8', 'fluid', 'ounce']\n",
      "['philips', 'norelco', 'arcitec', '1090', 'men', \"'s\", 'shaving', 'system']\n",
      "['bonne', 'bell', 'smackers', 'bath', 'and', 'body', 'starburst', 'collection']\n",
      "['philips', 'sonicare', 'uv', 'sanitizer']\n",
      "['maggie', \"'s\", 'functional', 'organics', 'raspberry', 'navy', 'forest', '9-11']\n",
      "['essie', 'nail', 'polish', ',', 'cuticle', 'care', ',', 'primers', 'and', 'finishers']\n",
      "['sex', 'in', 'the', 'city', 'kiss', 'by', 'instyle', 'parfums', 'eau', 'de', 'parfum', 'spray', '3.4', 'oz']\n",
      "['wiseways', 'herbals', 'witch', 'hazel', 'salve', '1', 'oz', '.']\n",
      "['helen', 'of', 'troy', '1579', 'tangle', 'free', 'hot', 'air', 'brush', ',', 'white', ',', '3/4', 'inch', 'barrel']\n",
      "['dr.', 'woods', 'pure', 'almond', 'liquid', 'castile', 'soap', ',', '32', 'ounce']\n",
      "['american', 'crew', 'by', 'american', 'crew', ':', 'classic', 'body', 'wash', '15.2', 'oz']\n",
      "['kent', 'the', 'handmade', 'comb', '-', 'fine', 'and', 'coarse', 'toothed', 'pocket', 'comb', 'sawcut', 'r7t', ',', '130', 'mm']\n",
      "['urban', 'spa', 'moisturizing', 'booties', 'to', 'keep', 'your', 'feet', 'smooth', ',', 'hydrated', 'and', 'moisturized']\n",
      "['plantlife', 'sandalwood', 'soap', 'bar', ',', '4', 'ounce']\n",
      "['ageless', ':', 'ultramax', 'gold', 'capsules', ',', '90', 'count']\n",
      "['avalon', 'organics', 'vitamin', 'c', 'renewal', 'creme', ',', '2', 'oz']\n",
      "['maui', 'rain', 'hawaiian', 'perfume']\n",
      "['whish', 'coconut', 'shaving', 'cream', '-', 'smooth', ',', 'all', 'natural', 'shave', 'cream', 'for', 'men', '&', 'amp', ';', 'women', ',', 'leaves', 'skin', 'so', 'soft', ',', 'shea', 'butter', 'and', 'coconut', 'oil', ',', 'natural', 'and', 'organic', 'skin', 'care', '-', '5', 'oz', '.', 'pump']\n",
      "['bath', '&', 'amp', ';', 'body', 'works', 'ile', 'de', 'tahiti', 'moana', 'coconut', 'vanille', 'moana', 'body', 'wash', 'with', 'tamanoi', '8.5', 'oz']\n",
      "['williams', 'lectric', 'shave', ',', '7', 'ounce']\n",
      "['fusionbeauty', 'liftfusion', 'face', 'lift']\n",
      "['organic', 'fiji', 'raw', 'organic', 'coconut', 'oil', ',', '13-ounce', 'jars']\n",
      "['nag', 'champa', 'super', 'hit', 'cones', ',', '144', 'cones', 'box']\n",
      "['axe', 'shower', 'tool', ',', 'detailer', '1', 'ea', ',', 'pack', 'of', '4']\n",
      "['clubman', 'lustray', 'blue', 'spice', 'after', 'shave', ',', '128', 'fluid', 'ounce']\n",
      "['clean', '&', 'amp', ';', 'clear', 'deep', 'action', 'cream', 'facial', 'cleanser', 'for', 'sensitive', 'skin', ',', 'gentle', 'daily', 'face', 'wash', 'with', 'oil-free', ',', '6.5', 'oz', '(', 'pack', 'of', '4', ')']\n",
      "['colgate', 'fluoride', 'toothpaste', 'strawberry', 'smash', 'liquid', 'gel', '4.60', 'oz', '(', 'pack', 'of', '6', ')']\n",
      "['oral-b', 'glide', 'pro-health', 'dental', 'floss', ',', 'original', 'floss', ',', '50m', ',', 'pack', 'of', '6']\n",
      "['pre', 'de', 'provence', 'maison', 'french', 'dried', 'lavender', 'blossoms', 'for', 'fragrance']\n",
      "['avalon', 'grapefruit', 'and', 'geranium', 'smoothing', 'shampoo', ',', '11', 'ounce']\n",
      "['astra', 'platinum', 'double', 'edge', 'safety', 'razor', 'blades', ',100', 'blades', '(', '20', 'x', '5', ')']\n",
      "['urban', 'spa', 'natural', 'bamboo', 'and', 'jute', 'bath', 'mitt']\n",
      "['kate', 'somerville', '&', 'nbsp', ';', 'exfolikate', 'intensive', '&', 'nbsp', ';', 'exfoliating', 'treatment', '&', 'nbsp', ';', '(', '5', 'fl', '.', 'oz', '.', 'luxury', 'size', ')']\n",
      "['bvlgari', 'white', 'by', 'bvlgari', 'for', 'men', 'and', 'women', ':', 'shampoo', '6.8', 'oz']\n",
      "['folicure', 'shampoo', 'extra', 'body', '12', 'oz', '.', '(', '3-pack', ')', 'with', 'free', 'nail', 'file']\n",
      "['aquaphor', 'healing', 'ointment', ',', 'advanced', 'therapy', 'skin', 'protectant', '14', 'ounce', '(', 'pack', 'may', 'vary', ')']\n",
      "['nars', 'blush', ',', 'gaiety']\n",
      "['dark', 'and', 'lovely', 'beautiful', 'beginnings', 'shampoo', ',', '10', 'fluid', 'ounce']\n",
      "['revitalash', 'by', 'revitalash', 'revitalash', 'advanced', 'eyelash', 'conditioner', '--', '3.5', 'ml', '/', '.118', 'oz']\n",
      "['colgate', 'enamel', 'health', 'mouthwash']\n",
      "['andalou', 'naturals', 'clementine', '+', 'c', 'illuminating', 'toner', ',', '6', 'fl', 'oz', ',', 'facial', 'toner', 'helps', 'hydrate', '&', 'amp', ';', 'balance', 'skin', 'ph', ',', 'for', 'clear', ',', 'bright', 'skin']\n",
      "['hammam', 'el', 'hana', 'argan', 'therapy', 'egyptian', 'white', 'musk', 'body', 'lotion', '13.5', 'fl.oz', '.', 'from', 'turkey']\n",
      "['mad', 'hippie', 'face', 'cream', 'with', 'anti', 'wrinkle', 'peptide', 'complex', '1.0', 'ounces']\n",
      "['pantene', 'pro-v', 'ultimate', '10', '2-in-1', 'shampoo', 'and', 'conditioner', '25.4', 'fl', 'oz', '(', 'packaging', 'may', 'vary', ')']\n",
      "['jhirmack', 'silver', 'plus', 'shampoo', 'ageless', '13.6', 'oz', '.', '(', 'pack', 'of', '6', ')']\n",
      "['victoria', \"'s\", 'secret', 'dream', 'angels', 'heavenly', 'angel', 'wash', '7.6', 'oz']\n",
      "['crest', '+', 'oral-b', 'professional', 'gingivitis', 'kit', ',', '1', 'count']\n",
      "['crest', 'pro-health', 'for', 'life', 'cpc', 'antigingivitis/antiplaque', 'smooth', 'mint', 'rinse', '33.8', 'fl', 'oz']\n",
      "['toni', '&', 'amp', ';', 'guy', 'glamour', 'volume', 'plumping', 'whip', ',', '2.82', 'fluid', 'ounce']\n",
      "['fekkai', 'full', 'blown', 'aerosol', 'foam', 'cond', 'us', '6.6', 'oz', ',', '6.660-fluid', 'ounce']\n",
      "['home', 'health', 'evercln', ',', 'face', 'cream', ',', '1.69', 'fluid', 'ounce']\n",
      "['eo', 'shower', 'gel', 'grapefruit', '&', 'amp', ';', 'mint', '32', 'oz']\n",
      "['spongelle', 'wild', 'flower', '14+', 'uses', 'body', 'wash', 'buffer', ',', 'french', 'lavender', ',', '4.25', '&', 'quot', ';', 'x', '1.25', '&', 'quot', ';']\n",
      "['caress', 'body', 'wash', '-', 'sheer', 'twilight', '-', '18', 'oz', '-', '2', 'pk']\n",
      "['crest', 'sensi-stop', 'strips', ',', '10', 'count']\n",
      "['rimmel', 'provocalips', '16hr', 'kissproof', 'lipstick', ',', 'kiss', 'fatal', ',', '0.14', 'fluid', 'ounce']\n",
      "['peter', 'lamas', 'wheatgrass', 'purifying', 'shampoo', 'and', 'conditioner', 'set', ',', '12', 'fluid', 'ounce', 'each']\n",
      "['pantene', 'pro-v', 'volume', 'conditioner', '12.0', 'fluid', 'ounce', '(', 'product', 'size', 'may', 'vary', ')']\n",
      "['oznaturals', 'anti', 'aging', 'retinol', 'serum', '-the', 'most', 'effective', 'anti', 'wrinkle', 'serum', 'contains', 'professional', 'strength', 'retinol+', 'astaxanthin+', 'vitamin', 'e', '-', 'get', 'the', 'dramatic', 'youthful', 'results', 'you', '&', 'rsquo', ';', 've', 'been', 'looking', 'for']\n",
      "['theorie', 'argan', 'oil', 'ultimate', 'reform', 'shampoo', '&', 'amp', ';', 'conditioner', '27', 'fl', 'oz', 'each']\n",
      "['sexy', 'straight', 'smooth', 'and', 'seal', 'hair', 'spray', '8.1', 'ounce', '(', 'pack', 'of', '3', ')']\n",
      "['lucia', 'flowers', 'print', 'brown', 'large', 'hair', 'clip', 'clamp']\n",
      "['(', 'pack', 'of', '3', ')', 'l.a.', 'colors', 'mineral', 'pressed', 'powder', '#', 'mp303', '&', 'quot', ';', 'creamy', 'natural', '&', 'quot', ';']\n",
      "['naturelle', 'hypo-allergenic', 'styling', 'gel']\n",
      "['pre', 'de', 'provence', 'artisanal', 'french', 'soap', 'bar', 'enriched', 'with', 'shea', 'butter', ',', 'quad-milled', 'for', 'a', 'smooth', '&', 'amp', ';', 'rich', 'lather', '(', '150', 'grams', ')', '-', 'raspberry']\n",
      "['dove', 'men+care', ',', 'deep', 'clean', 'body', '+', 'face', 'bar', ',', '4', 'ounce', ',', '6', 'count', ',', '(', 'pack', 'of', '2', ')', '&', 'hellip', ';']\n",
      "['lectric', 'shave', 'pre-shave', 'original', '3', 'oz']\n",
      "['pre', 'de', 'provence', 'maison', 'french', 'lavender', 'bath', '&', 'amp', ';', 'shower', 'gel']\n",
      "['ultimate', 'body', 'lotion', 'by', 'michael', 'kors', '3.4oz']\n",
      "['dolce', '&', 'amp', ';', 'gabbana', 'compact', 'parfum', ',', '0.05', 'ounce']\n",
      "['colgate', 'kids', 'maximum', 'cavity', 'protection', 'pump', 'toothpaste', '-', '4.4', 'ounce', '(', '12', 'pack', ')']\n",
      "['bali', 'secrets', 'natural', 'deodorant', '-', 'organic', '&', 'amp', ';', 'vegan', '-', 'for', 'women', '&', 'amp', ';', 'men', '-', 'all', 'day', 'fresh', '-', 'strong', '&', 'amp', ';', 'reliable', 'protection', '-', '2.5', 'fl.oz/75ml', '[', 'scent', ':', 'sandalwood', ']']\n",
      "['essie', 'gel', 'couture', 'nail', 'polish']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/recsys/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(vocabulary=corpus_filtered_tokens, tokenizer=lambda x: x.split(' '))\n",
    "processed_titles = [preprocessing(title) for title in item_titles]\n",
    "X = vectorizer.fit_transform(processed_titles)\n",
    "\n",
    "# (84, 471) is interpreted as for each document we have entry for each word from our vocab. Each entry uses the tf-idf formula for the calculating of the significance of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fruit amp passion blue refresh shower gel 6.7 fl oz'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_titles[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 471)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-gnTVM0EV_2d"
   },
   "source": [
    "## 2.2\n",
    "\n",
    "Using the TF-IDF representation, compute the cosine similarity between products with asin `B000FI4S1E`, `B000LIBUBY` and `B000W0C07Y`. Take a look at their features to see whether results make sense with their characteristics. Round your final answer to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zO_OHMY8PWbO",
    "outputId": "8fd3f26c-7adc-4c95-a8ce-febdabe05406"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.03075944, 0.02377955],\n",
       "       [0.03075944, 1.        , 0.50060985],\n",
       "       [0.02377955, 0.50060985, 1.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "asin1 = 'B000FI4S1E' \n",
    "asin2 = 'B000LIBUBY'\n",
    "asin3 = 'B000W0C07Y'\n",
    "\n",
    "asin1_title = filtered_item_metadata[filtered_item_metadata.asin == asin1].title.tolist()[0]\n",
    "asin2_title = filtered_item_metadata[filtered_item_metadata.asin == asin2].title.tolist()[0]\n",
    "asin3_title = filtered_item_metadata[filtered_item_metadata.asin == asin3].title.tolist()[0]\n",
    "\n",
    "asin1_title_index = item_titles.index(asin1_title)\n",
    "asin2_title_index = item_titles.index(asin2_title)\n",
    "asin3_title_index = item_titles.index(asin3_title)\n",
    "\n",
    "cosine_similarity(X[[asin1_title_index,asin2_title_index,asin3_title_index]],X[[asin1_title_index,asin2_title_index,asin3_title_index]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0K8jRhWhZQWe"
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "Representation in vector spaces with contextual Word Embeddings.\n",
    "\n",
    "## 3.1.\n",
    "\n",
    "Represent all the products from Exercise 1 in a vector space using embeddings from a pre-trained BERT model. The final embedding of a product should be the average of the word embeddings from all the words in the 'title'. Critically evaluate this procedure.\n",
    "\n",
    "What is the vocabulary size of the model? What are the dimensions of the last hidden state?\n",
    "\n",
    "Tip: you may install the transformers library and use their pretrained [BERT model uncased](https://huggingface.co/bert-base-uncased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment and run the following line to install the transformers library\n",
    "# ! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHIjJ-LbTB3H",
    "outputId": "0bec9e50-22cc-4463-8daf-d3c62b66d0cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/recsys/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/recsys/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <0B7EB158-53DC-3403-8A49-22178CAB4612> /opt/anaconda3/envs/recsys/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/anaconda3/envs/recsys/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/recsys/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/recsys/lib/python3.10/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/recsys/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "30522\n",
      "Max input size: 512\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "# LOAD TRANSFORMER\n",
    "\"\"\"\n",
    "If you plan on using a pretrained model, it’s important to use the associated \n",
    "pretrained tokenizer: it will split the text you give it in tokens the same way\n",
    "for the pretraining corpus, and it will use the same correspondence\n",
    "token to index (that we usually call a vocab) as during pretraining.\n",
    "\"\"\"\n",
    "\n",
    "# % pip install transformers\n",
    "import torch\n",
    "import transformers\n",
    "assert transformers.__version__ > '4.0.0'\n",
    "\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "\n",
    "# set-up environment\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "\n",
    "modelname = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(modelname)\n",
    "model = BertModel.from_pretrained(modelname).to(DEVICE)\n",
    "\n",
    "# Print out the vocabulary size\n",
    "print(tokenizer.vocab_size)\n",
    "print(f\"Max input size: {tokenizer.model_max_length}\")\n",
    "print(model.config.hidden_size)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_Symyv5U07x",
    "outputId": "580c6162-03ef-4041-d4a9-c2552181d4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 28319, 2310, 22144, 2044, 27545, 1010, 4438, 3256, 2630, 1010, 1021, 19471, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "last_hidden_states: torch.Size([84, 52, 768])\n"
     ]
    }
   ],
   "source": [
    "# Represent products in a vector space\n",
    "\"\"\"\n",
    "When using pre-trained models, it is always advised to feed it data similar to what it was trained with. \n",
    "Basically, it doesn't hurt to keep all the words in.\n",
    "However, the effect (or the lack of it) will vary based on corpus and task. \n",
    "Decision here: keep them all since pretraining was done that way.\n",
    "\"\"\"\n",
    "\n",
    "def batch_encoding(sentences):\n",
    "    # Since we're using padding, we need to provide the attention masks to our\n",
    "    # model. Otherwise it doesn't know which tokens it should not attend to. \n",
    "    inputs = tokenizer(sentences, padding=True, return_tensors='pt') # Make the tokenizer return encoded sequences with padding in pytorch tensor format\n",
    "    print(inputs[0].attention_mask) # Look at the padding and attention_mask\n",
    "    print(inputs[0].ids) # Look at the padding and attention_mask\n",
    "\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "    return inputs, inputs[\"attention_mask\"], last_hidden_states\n",
    "  \n",
    "encoded_inputs, attention_masks, title_last_hidden_states = batch_encoding(\n",
    "                                                          filtered_item_metadata.title.tolist()  \n",
    "                                                            )\n",
    "# Note that the control token [CLS] has been added at the beginning of each sentence,\n",
    "# and [SEP] at the end\n",
    "\n",
    "print(f\"last_hidden_states: {title_last_hidden_states.shape}\")\n",
    "# Let's mask out the padding tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84, 52])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5125, -0.6032, -0.0640,  ..., -0.0243, -0.5474,  0.0653],\n",
       "         [ 0.6216, -0.2028,  0.0255,  ..., -0.1496,  0.1825,  0.6196],\n",
       "         [-0.1194, -1.0340,  0.9036,  ...,  0.2274, -0.3123,  0.1688],\n",
       "         ...,\n",
       "         [ 0.3163, -0.2145,  0.4271,  ..., -0.0255, -0.2990,  0.1332],\n",
       "         [ 0.5335, -0.2718,  0.4228,  ..., -0.2108, -0.2156, -0.0760],\n",
       "         [ 0.2494, -0.0511,  0.2910,  ..., -0.0092, -0.2357,  0.0571]],\n",
       "\n",
       "        [[-0.8001, -0.3167,  0.2363,  ..., -0.3909, -0.4204,  0.2607],\n",
       "         [ 0.5632, -0.2454,  0.4371,  ...,  0.1749,  0.0928,  0.3471],\n",
       "         [-0.0806, -0.2830,  0.6450,  ...,  0.3591, -0.4115, -0.0125],\n",
       "         ...,\n",
       "         [-0.2381,  0.2319,  0.3110,  ...,  0.2153, -0.3523,  0.3913],\n",
       "         [ 0.1254,  0.3215,  0.1888,  ...,  0.2091, -0.0579,  0.3087],\n",
       "         [-0.0851,  0.3480,  0.2515,  ...,  0.1133, -0.2591,  0.1225]],\n",
       "\n",
       "        [[-0.5316, -0.2055, -0.1992,  ..., -0.4426,  0.3019,  0.4350],\n",
       "         [ 0.2200, -0.7475,  0.0666,  ..., -1.1324,  0.3589,  0.0998],\n",
       "         [-0.4059,  0.3309,  0.8910,  ..., -0.4544, -0.2928, -0.2574],\n",
       "         ...,\n",
       "         [ 0.0762,  0.0342,  0.3556,  ..., -0.2252,  0.1857, -0.0780],\n",
       "         [-0.0610, -0.0528,  0.2580,  ..., -0.1570,  0.2266, -0.0392],\n",
       "         [-0.0959, -0.0457,  0.2771,  ..., -0.1848,  0.1826, -0.0222]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.6185, -0.2401,  0.3043,  ..., -0.1729, -0.1313, -0.1037],\n",
       "         [-0.5621,  0.0378,  0.1680,  ...,  0.4880,  0.6087,  0.4962],\n",
       "         [ 0.0531,  0.2777,  0.2553,  ...,  0.3598,  0.1526, -0.3363],\n",
       "         ...,\n",
       "         [-0.4146, -0.6005, -0.2101,  ..., -0.0379, -0.3021, -0.3341],\n",
       "         [-0.1345, -0.2128,  0.0713,  ..., -0.1159, -0.4046, -0.2024],\n",
       "         [ 0.0864,  0.1110,  0.2919,  ..., -0.0150, -0.3916,  0.0296]],\n",
       "\n",
       "        [[-0.6331, -0.4754, -0.1243,  ..., -0.1777, -0.1788,  0.3864],\n",
       "         [ 0.4942, -0.1956, -0.0589,  ...,  0.2592,  0.1562,  0.1958],\n",
       "         [ 0.2658, -0.5886, -0.1258,  ..., -0.0881, -0.0838,  0.0169],\n",
       "         ...,\n",
       "         [ 0.0732, -0.2658,  0.2465,  ...,  0.1836,  0.0805, -0.2930],\n",
       "         [ 0.6801,  0.4317, -0.1866,  ...,  0.0782, -0.6472, -0.4373],\n",
       "         [ 0.0949, -0.1751,  0.0670,  ...,  0.2155, -0.1875, -0.0630]],\n",
       "\n",
       "        [[-0.1278, -0.3458,  0.0674,  ..., -0.5269, -0.4106,  0.0146],\n",
       "         [ 0.1935, -0.5517,  0.7682,  ..., -0.2100,  0.3414,  0.0742],\n",
       "         [ 0.1772, -0.6405,  0.9007,  ..., -0.1260, -0.2904, -0.7388],\n",
       "         ...,\n",
       "         [ 0.1364, -0.7863, -0.4772,  ..., -0.5386, -0.4143, -0.3289],\n",
       "         [ 0.4161, -0.2147,  0.0930,  ..., -0.4879, -0.1218, -0.1162],\n",
       "         [ 0.4064, -0.1685,  0.1002,  ..., -0.5072, -0.1290, -0.1181]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84, 52, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_embeddings = torch.sum(title_last_hidden_states * attention_masks.unsqueeze(-1), dim=1)\n",
    "sentence_embeddings = (avg_embeddings / attention_masks.sum(dim=1, keepdim=True)).detach().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EwRBr2HP0Zdt"
   },
   "source": [
    "## 3.2.\n",
    "\n",
    "Using the representation obtained from Exercise 3.1., compute the cosine similarity between items with asin `B000FI4S1E`, `B000LIBUBY` and `B000W0C07Y`.\n",
    "Round your final answer to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaHxSLHqItNs",
    "outputId": "1f964bb4-5c37-4278-cccf-848e7b552183"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999997 , 0.73359346, 0.6593505 ],\n",
       "       [0.73359346, 1.0000006 , 0.7475123 ],\n",
       "       [0.6593505 , 0.7475123 , 1.0000002 ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "asin1 = 'B000FI4S1E' \n",
    "asin2 = 'B000LIBUBY'\n",
    "asin3 ='B000W0C07Y'\n",
    "\n",
    "asin1_title = filtered_item_metadata[filtered_item_metadata.asin == asin1].title.tolist()[0]\n",
    "asin2_title = filtered_item_metadata[filtered_item_metadata.asin == asin2].title.tolist()[0]\n",
    "asin3_title = filtered_item_metadata[filtered_item_metadata.asin == asin3].title.tolist()[0]\n",
    "\n",
    "asin1_title_index = item_titles.index(asin1_title)\n",
    "asin2_title_index = item_titles.index(asin2_title)\n",
    "asin3_title_index = item_titles.index(asin3_title)\n",
    "\n",
    "cosine_similarity(sentence_embeddings[[asin1_title_index,asin2_title_index,asin3_title_index]],sentence_embeddings[[asin1_title_index,asin2_title_index,asin3_title_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Session_4-Text-Representation-solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
